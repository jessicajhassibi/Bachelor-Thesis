{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1a5d056",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded spacy language model: de_core_news_sm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from data import get_documents_list, get_cleaned_dataframe_with_topics, get_cleaned_dataframe, get_sentences_and_labels_lists\n",
    "from models import classification, get_embedding_model, get_BERTopic_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a57be6",
   "metadata": {},
   "source": [
    "For monolingual execution, please change WIKI_LANGUAGES in config.ini file to language code of language you want to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f4ff11",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "load the preprocessed texts in defined languages into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "244d06eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = get_cleaned_dataframe_with_topics() #todo:fix\n",
    "df = get_cleaned_dataframe()\n",
    "documents = get_documents_list('cleaned_sentences')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cd7a4c",
   "metadata": {},
   "source": [
    "Decide what types of documents you want to train your embedding model on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0454bf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Embedding Model\n",
    "Choose method and text_type the document was trained on.\n",
    "### Parameters:\n",
    "- method = \"muse\", \"fastText\", or \"Word2Vec\"\n",
    "- Optional: text_type = \"cleaned_texts\", \"cleaned_texts_topics\", ... (see more in embedding_models.py)\n",
    "- Optional: training_type = \"pretrained_aligned\" or \"from_scratch\"\n",
    "\n",
    "e.g. use method = \"muse\", text_type='cleaned_texts', training_type = \"pretrained_aligned\" for pretrained aligned models downloaded from facebookresearch MUSE website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33c5c54b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  /home/Bachelor-Thesis/models/classification/FastText/FastText_de_cleaned_sentences  loaded\n"
     ]
    }
   ],
   "source": [
    "model, word_vectors = get_embedding_model(documents, text_type = \"cleaned_sentences\", method = \"fastText\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bea68364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999891"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similarity('composer', 'komponist')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78fe7be",
   "metadata": {},
   "source": [
    "## Split data into train and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76447f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# case for full texts:\n",
    "#X_train, X_test, y_train, y_test = train_test_split(df['cleaned_texts'], df['label'] , test_size=0.2)\n",
    "\n",
    "# case for sentences\n",
    "docs, targets = get_sentences_and_labels_lists()\n",
    "X_train, X_test, y_train, y_test = train_test_split(docs, targets , test_size=0.2)\n",
    "\n",
    "import pandas as pd\n",
    "X_train = pd.Series(X_train) \n",
    "X_test = pd.Series(X_test) \n",
    "y_train = pd.Series(y_train) \n",
    "y_test = pd.Series(y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e54281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = classification.text2vec(X_train, word_vectors)\n",
    "X_test_vect = classification.text2vec(X_test, word_vectors)\n",
    "X_train_vect_avg = classification.average_text_vector(X_train_vect)\n",
    "X_test_vect_avg = classification.average_text_vector(X_test_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb872f2",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab05d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(sampling_strategy=\"not majority\")\n",
    "X_train_2d = X_train.values.reshape(-1, 1) # puts each elem of array in own array\n",
    "X_res, y_res = ros.fit_resample(X_train_2d, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d8048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_res.value_counts())\n",
    "y_res.value_counts().plot.pie(autopct='%0.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b25b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_res revert 2_dimensionality\n",
    "X_res_1d = X_res.flatten()\n",
    "\n",
    "# classification with resampled vectors\n",
    "X_res_vect = classification.text2vec(X_res_1d, word_vectors)\n",
    "X_res_vect_avg = classification.average_vector(X_res_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1492092",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res_pred = classification.classify_predict(X_res_vect_avg, X_test_vect_avg, y_res, \"Random Forest\")\n",
    "classification.print_classification_report(y_test, y_res_pred)\n",
    "y_res_pred = classification.classify_predict(X_res_vect_avg, X_test_vect_avg, y_res, \"Multinomial Naive Bayes\")\n",
    "classification.print_classification_report(y_test, y_res_pred)\n",
    "y_res_pred = classification.classify_predict(X_res_vect_avg, X_test_vect_avg, y_res, \"SVM\")\n",
    "classification.print_classification_report(y_test, y_res_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis] *",
   "language": "python",
   "name": "conda-env-thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
