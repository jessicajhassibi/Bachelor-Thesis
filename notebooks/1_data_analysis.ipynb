{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Perform some analysis over scraped wikipedia.\n",
    "How many articles in each language and so on…"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from data import data_analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_helpers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m languages_count_dict \u001B[38;5;241m=\u001B[39m \u001B[43mdata_analysis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlanguage_analyzer\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Private/funstuff/IdeaProjects/Bachelor-Thesis/src/data/data_analysis.py:34\u001B[0m, in \u001B[0;36mlanguage_analyzer\u001B[0;34m()\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;66;03m# get counts\u001B[39;00m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m lang \u001B[38;5;129;01min\u001B[39;00m get_languages():\n\u001B[0;32m---> 34\u001B[0m     dfs \u001B[38;5;241m=\u001B[39m [\u001B[43mdata_helpers\u001B[49m\u001B[38;5;241m.\u001B[39mget_dataframe_from_json(\n\u001B[1;32m     35\u001B[0m         \u001B[38;5;28mstr\u001B[39m(get_persecuted_composers_path()\u001B[38;5;241m.\u001B[39mjoinpath(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlang\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_texts_composers_persecuted.json\u001B[39m\u001B[38;5;124m\"\u001B[39m))),\n\u001B[1;32m     36\u001B[0m         data_helpers\u001B[38;5;241m.\u001B[39mget_dataframe_from_json(\n\u001B[1;32m     37\u001B[0m             \u001B[38;5;28mstr\u001B[39m(get_supported_composers_path()\u001B[38;5;241m.\u001B[39mjoinpath(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlang\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_texts_composers_supported.json\u001B[39m\u001B[38;5;124m\"\u001B[39m)))]\n\u001B[1;32m     39\u001B[0m     a, p, w \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     40\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m df \u001B[38;5;129;01min\u001B[39;00m dfs:\n",
      "\u001B[0;31mNameError\u001B[0m: name 'data_helpers' is not defined"
     ]
    }
   ],
   "source": [
    "languages_count_dict = data_analysis.language_analyzer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0a6b77",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating autocpt arguments\n",
    "def pct_func(pct, allvalues):\n",
    "    absolute = int(pct / 100.*np.sum(allvalues))\n",
    "    return \"{:.1f}%\\n({:d})\".format(pct, absolute)\n",
    "\n",
    "# 3 Pie charts to be side by side\n",
    "fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(20,20))\n",
    "\n",
    "# Plotting articles pie chart\n",
    "sizes = [languages_count_dict[lang][\"articles\"] for lang in languages_count_dict.keys()]\n",
    "ax1.pie(sizes, labels = data_analysis.get_languages(), autopct = lambda pct: pct_func(pct, sizes))\n",
    "ax1.set_title(\"Verteilung der Artikel\")\n",
    "\n",
    "# Plotting paragraphs pie chart\n",
    "sizes = [languages_count_dict[lang][\"paragraphs\"] for lang in languages_count_dict.keys()]\n",
    "ax2.pie(sizes, labels = languages,autopct = lambda pct: pct_func(pct, sizes))\n",
    "ax2.set_title(\"Verteilung der Paragraphen\")\n",
    "\n",
    "# Plotting words pie chart\n",
    "sizes = [languages_count_dict[lang][\"words\"] for lang in languages_count_dict.keys()]\n",
    "ax3.pie(sizes, labels = languages,autopct = lambda pct: pct_func(pct, sizes))\n",
    "ax3.set_title(\"Verteilung der Wörter\")\n",
    "\n",
    "# get current figure\n",
    "fig_out = plt.gcf() \n",
    "\n",
    "# show plot\n",
    "plt.show()\n",
    "\n",
    "# save plot\n",
    "fig_out.savefig(\"../reports/figures/Sprachverteilungen.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58395fda",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting the 20 articles with most words etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a29d25c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# wieviel prozent der artikel in den versch. sprachen da\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis] *",
   "language": "python",
   "name": "conda-env-thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}