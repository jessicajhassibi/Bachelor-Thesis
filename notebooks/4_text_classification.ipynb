{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1a5d056",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded spacy language model: de_core_news_sm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data import get_documents_list, get_cleaned_dataframe_with_topics, \\\n",
    "get_cleaned_dataframe, get_data_and_labels_lists, get_datasets_embedding_classification_path\n",
    "from models import classification, get_embedding_model\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a57be6",
   "metadata": {},
   "source": [
    "For monolingual execution, please change WIKI_LANGUAGES in config.ini file to language code of language you want to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546f3933",
   "metadata": {},
   "source": [
    "### Choose Parameters: \n",
    "- method = \"muse\", \"fastText\", or \"Word2Vec\"\n",
    "    -> embedding model \n",
    "- text_type = \"cleaned_texts\", \"cleaned_texts_topics\", ... (see more in embedding_models.py)\n",
    "    -> documents the model was trained on and to do classification on\n",
    "- training_type = \"pretrained_aligned\" or \"from_scratch\"\n",
    "    -> type of training which was used\n",
    "    \n",
    "e.g. use method = \"muse\", text_type='cleaned_texts', training_type = \"pretrained_aligned\" for pretrained aligned models downloaded from facebookresearch MUSE website"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f4ff11",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "load the preprocessed texts in defined languages into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cb331f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_on = \"cleaned_texts\"\n",
    "X_train_path = get_datasets_embedding_classification_path().joinpath(f'X_train_{classify_on}.csv')\n",
    "X_test_path = get_datasets_embedding_classification_path().joinpath(f'X_test_{classify_on}.csv')\n",
    "y_train_path = get_datasets_embedding_classification_path().joinpath(f'y_train_{classify_on}.csv')\n",
    "y_test_path = get_datasets_embedding_classification_path().joinpath(f'y_test_{classify_on}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c26d1d",
   "metadata": {},
   "source": [
    "## Load train and test data  if already splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8a2945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = pd.read_csv(X_train_path)\n",
    "#X_test = pd.read_csv(X_test_path)\n",
    "#y_train = pd.read_csv(y_train_path)\n",
    "#y_test = pd.read_csv(y_test_path)\n",
    "#X_train=X_train.drop([0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84426ea",
   "metadata": {},
   "source": [
    "## Split data into train and test sets\n",
    "- run it just once for classify_on = \"cleaned_texts_topics\" and \"cleaned_texts\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b42936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_cleaned_dataframe_with_topics(num_topics=3)\n",
    "df = df[[classify_on, 'label']].copy()\n",
    "df = df.rename(columns={classify_on: 'data'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76447f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['data'], df['label'] , test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53496e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath, data in [(X_train_path, X_train),\\\n",
    "                        (X_test_path, X_test), \\\n",
    "                        (y_train_path, y_train),\\\n",
    "                  (y_test_path, y_test)]:\n",
    "    data.to_csv(filepath,index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cd7a4c",
   "metadata": {},
   "source": [
    "Decide what types of documents you want to train your embedding model on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0454bf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Embedding Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba5fc05",
   "metadata": {},
   "source": [
    "NOTE FOR TRAINING NEW MODEL: \n",
    "    \n",
    "For multilingual fastText Model first train monolingual fastText models (use parameter method=\"fastText\"). \n",
    "Then use muse library to align the embeddings: https://github.com/facebookresearch/MUSE\n",
    "The command could look like this (supervised): \n",
    "``` shell\n",
    "python supervised.py --src_lang en --tgt_lang de --src_emb /Users/jessicahassibi/Bachelor-Thesis/models/classification/FastText/FastText_en_cleaned_texts.vec --tgt_emb /Users/jessicahassibi/Bachelor-Thesis/models/classification/FastText/FastText_de_cleaned_texts.vec --n_refinement 5 --dico_train default --cuda=False\n",
    "```\n",
    "or like this (unsupervised):\n",
    "``` shell\n",
    "python unsupervised.py --src_lang en --tgt_lang de --src_emb /Users/jessicahassibi/Bachelor-Thesis/models/classification/FastText/FastText_en_cleaned_texts.vec --tgt_emb /Users/jessicahassibi/Bachelor-Thesis/models/classification/FastText/FastText_de_cleaned_texts.vec --n_refinement 5 --cuda=False\n",
    "```\n",
    "\n",
    "Place the aligned vectors to /models/classification/FastText/aligned_embeddings and use code in next cell with method=\"muse\" to combine those embeddings and get multilingual word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eab685fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"fastText\"\n",
    "training_type = \"from_scratch\"\n",
    "trained_on = \"cleaned_texts\"\n",
    "classify_on = \"cleaned_texts\"\n",
    "docs = get_documents_list(classify_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33c5c54b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  /home/Bachelor-Thesis/models/classification/FastText/FastText_de_cleaned_texts  loaded\n"
     ]
    }
   ],
   "source": [
    "model, word_vectors = get_embedding_model(docs, text_type = trained_on, training_type = training_type, method = method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bea68364",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_vectors.similarity('composer', 'komponist')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01e0697",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## Text Classification on manually trained Embedding model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c176b21d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create features from text for machine learning model.\n",
    "Steps:\n",
    "- Turn words in texts into word vectors.\n",
    "- averaging word vectors for each text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "698fee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = classification.text2vec(X_train, word_vectors)\n",
    "X_test_vect = classification.text2vec(X_test, word_vectors)\n",
    "\n",
    "X_train_vect_avg = classification.average_text_vector(X_train_vect)\n",
    "X_test_vect_avg = classification.average_text_vector(X_test_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a657c0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Intuition for Classification reports:\n",
    "- Recall = how many of this class where found over whole num of elements of this class\n",
    "- Precision = how many correctly classified among that class\n",
    "- Accuracy = num of correct predictions/ num of total predictions\n",
    "- f1-score: harmonic mean between precision and recall\n",
    "- support: num of occurrence of given class in dataset\n",
    "\n",
    "- recall macro avg = (recall_class_1 + recall_class_0) / 2\n",
    "- recall weighted avg = (support_class_0 * recall_class_0 + support_class_1 * recall_class_1) / (support_class_0 + support_class_1)\n",
    "- scikit learn classification_report average parameter explanation:\n",
    "\n",
    "-average=micro: compute f1 by considering total true positives, false negatives and false positives (no matter of the prediction for each label in the dataset) (= Accuracy?)\n",
    "\n",
    "-average=macro: compute f1 for each label, and returns the average without considering the proportion for each label in the dataset. (treats all classes the same)\n",
    "\n",
    "-average=weighted: compute f1 for each label, and returns the average considering the proportion for each label in the dataset.\n",
    "\n",
    "-average=samples: compute f1 for each instance, and returns the average. Use it for multilabel classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05687a95",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Instantiate and fit a classificator model on top of the vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66856b9",
   "metadata": {},
   "source": [
    "Highly Imbalanced Dataset!\n",
    "Ideas:\n",
    "- Undersampling: reduce majority class to make it equal to minority class\n",
    "- Oversampling: increase minority class to make it equal to majority class through resampling\n",
    "- K-fold cross validation\n",
    "\n",
    "### Choose Parameter: \n",
    "- resampling = False, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a76f007",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION WITH:OVERSAMPLING\n",
      "0    175\n",
      "1    175\n",
      "Name: label, dtype: int64\n",
      "############################################################################\n",
      "Processing Multinomial Naive Bayes Classification\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    verfolgt       0.64      0.78      0.70        36\n",
      "    begnadet       0.20      0.11      0.14        18\n",
      "\n",
      "    accuracy                           0.56        54\n",
      "   macro avg       0.42      0.44      0.42        54\n",
      "weighted avg       0.49      0.56      0.51        54\n",
      "\n",
      "classes in y_pred: {0, 1} classes in y_test: {0, 1}\n",
      "############################################################################\n",
      "############################################################################\n",
      "Processing SVM Classification\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    verfolgt       0.64      0.78      0.70        36\n",
      "    begnadet       0.20      0.11      0.14        18\n",
      "\n",
      "    accuracy                           0.56        54\n",
      "   macro avg       0.42      0.44      0.42        54\n",
      "weighted avg       0.49      0.56      0.51        54\n",
      "\n",
      "classes in y_pred: {0, 1} classes in y_test: {0, 1}\n",
      "############################################################################\n",
      "CLASSIFICATION WITH:UNDERSAMPLING\n",
      "0    37\n",
      "1    37\n",
      "Name: label, dtype: int64\n",
      "############################################################################\n",
      "Processing Multinomial Naive Bayes Classification\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    verfolgt       0.61      0.79      0.69        34\n",
      "    begnadet       0.30      0.15      0.20        20\n",
      "\n",
      "    accuracy                           0.56        54\n",
      "   macro avg       0.46      0.47      0.45        54\n",
      "weighted avg       0.50      0.56      0.51        54\n",
      "\n",
      "classes in y_pred: {0, 1} classes in y_test: {0, 1}\n",
      "############################################################################\n",
      "############################################################################\n",
      "Processing SVM Classification\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    verfolgt       0.64      0.78      0.70        36\n",
      "    begnadet       0.20      0.11      0.14        18\n",
      "\n",
      "    accuracy                           0.56        54\n",
      "   macro avg       0.42      0.44      0.42        54\n",
      "weighted avg       0.49      0.56      0.51        54\n",
      "\n",
      "classes in y_pred: {0, 1} classes in y_test: {0, 1}\n",
      "############################################################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resampling = True\n",
    "colors = ['#66b3ff','#99ff99']\n",
    "if not resampling:\n",
    "    print(\"CLASSIFICATION WITHOUT SAMPLING:\")\n",
    "    #y_pred = classification.classify_predict(X_train_vect_avg, X_test_vect_avg, y_train, \"Random Forest\")\n",
    "    #classification.print_classification_report(y_test, y_pred)\n",
    "\n",
    "    y_pred = classification.classify_predict(X_train_vect_avg, X_test_vect_avg, y_train, \"Multinomial Naive Bayes\")\n",
    "    classification.print_classification_report(y_test, y_pred)\n",
    "\n",
    "    y_pred = classification.classify_predict(X_train_vect_avg, X_test_vect_avg, y_train, \"SVM\")\n",
    "    classification.print_classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(y_train.value_counts())\n",
    "    y_train.value_counts().plot.pie(autopct='%0.2f', colors=colors)\n",
    "    \n",
    "else:\n",
    "    ros = RandomOverSampler(sampling_strategy=\"not majority\")\n",
    "    rus = RandomUnderSampler(random_state=0, sampling_strategy=\"majority\")\n",
    "    \n",
    "    for sampler, method in [(ros, \"OVERSAMPLING\"),(rus, \"UNDERSAMPLING\")]:\n",
    "        print(f\"CLASSIFICATION WITH:{method}\")\n",
    "            \n",
    "        X_train_2d = X_train.values.reshape(-1, 1) # puts each elem of array in own array\n",
    "        X_res, y_res = sampler.fit_resample(X_train_2d, y_train)\n",
    "        \n",
    "        print(y_res.value_counts())\n",
    "        y_res.value_counts().plot.pie(autopct='%0.2f', colors=colors)\n",
    "        \n",
    "        #X_res revert 2_dimensionality\n",
    "        X_res_1d = X_res.flatten()\n",
    "\n",
    "        # classification with resampled vectors\n",
    "        X_res_vect = classification.text2vec(X_res_1d, word_vectors)\n",
    "        X_res_vect_avg = classification.average_text_vector(X_res_vect)\n",
    "\n",
    "        #y_res_pred = classification.classify_predict(X_res_vect_avg, X_test_vect_avg, y_res, \"Random Forest\")\n",
    "        #classification.print_classification_report(y_test, y_res_pred)\n",
    "        y_res_pred = classification.classify_predict(X_res_vect_avg, X_test_vect_avg, y_res, \"Multinomial Naive Bayes\")\n",
    "        classification.print_classification_report(y_test, y_res_pred)\n",
    "        y_res_pred = classification.classify_predict(X_res_vect_avg, X_test_vect_avg, y_res, \"SVM\")\n",
    "        classification.print_classification_report(y_test, y_res_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f562b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclassify_on = \"cleaned_texts_topics\"\\ndocs = list()\\n\\nif classify_on == \"cleaned_texts\":\\n    # case for texts\\n    df = get_cleaned_dataframe()\\n    df = df[[classify_on, \\'label\\']].copy()\\n    df = df.rename(columns={classify_on: \\'data\\'})\\n    docs = get_documents_list(\\'cleaned_texts\\')\\n    \\nelif classify_on == \"cleaned_texts_topics\":\\n    df = get_cleaned_dataframe_with_topics(num_topics=3)\\n    df = df[[classify_on, \\'label\\']].copy()\\n    df = df.rename(columns={classify_on: \\'data\\'})\\n    docs = get_documents_list(classify_on)\\n    \\nelif classify_on == \"cleaned_sentences\" or classify_on == \"cleaned_paragraphs\":\\n    # case for sentences and paragraphs\\n    docs, targets = get_data_and_labels_lists(classify_on)\\n    df = pd.DataFrame(list(zip(docs, targets)),\\n                   columns =[\\'data\\', \\'label\\'])\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to try training on different layers of data -> not used anymore in the end\n",
    "\"\"\"\n",
    "classify_on = \"cleaned_texts_topics\"\n",
    "docs = list()\n",
    "\n",
    "if classify_on == \"cleaned_texts\":\n",
    "    # case for texts\n",
    "    df = get_cleaned_dataframe()\n",
    "    df = df[[classify_on, 'label']].copy()\n",
    "    df = df.rename(columns={classify_on: 'data'})\n",
    "    docs = get_documents_list('cleaned_texts')\n",
    "    \n",
    "elif classify_on == \"cleaned_texts_topics\":\n",
    "    df = get_cleaned_dataframe_with_topics(num_topics=3)\n",
    "    df = df[[classify_on, 'label']].copy()\n",
    "    df = df.rename(columns={classify_on: 'data'})\n",
    "    docs = get_documents_list(classify_on)\n",
    "    \n",
    "elif classify_on == \"cleaned_sentences\" or classify_on == \"cleaned_paragraphs\":\n",
    "    # case for sentences and paragraphs\n",
    "    docs, targets = get_data_and_labels_lists(classify_on)\n",
    "    df = pd.DataFrame(list(zip(docs, targets)),\n",
    "                   columns =['data', 'label'])\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073cb890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5771220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis] *",
   "language": "python",
   "name": "conda-env-thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
