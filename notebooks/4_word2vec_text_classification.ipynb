{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1a5d056",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaCy pipeline loaded\n"
     ]
    }
   ],
   "source": [
    "from data import get_cleaned_dataframes, get_dataframes\n",
    "from models import ttl_word2vec, classification"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Word2Vec\n",
    "load the preprocessed texts in all languages into a dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cleaned_multilingual_dataframe = get_cleaned_dataframes()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split data into train and test sets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa00c8ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_multilingual_dataframe['cleaned_text'], cleaned_multilingual_dataframe['label'] , test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train a Word2Vec model with the train set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c5c54b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences=X_train, vector_size= 100, min_count=1) # sentences = wikipedia articles!"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "save that model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save(\"../models/multilingual_word2vec.model\")\n",
    "# save model as KeyedVectors\n",
    "wv = model.wv\n",
    "wv.save('../models/word_vectors/multilingual_word2vec.kv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "load model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Word2Vec.load('../models/multilingual_word2vec.model')\n",
    "wv = ttl_word2vec.load_word2vec_keyed_vectors('../models/word_vectors/multilingual_word2vec.kv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Text Classification on manually trained Word2Vec model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create features from text for machine learning model.\n",
    "Steps:\n",
    "- Turn words in texts into word vectors.\n",
    "- Method 1: averaging word vectors for each text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_vect = classification.text2vec(X_train, wv)\n",
    "X_test_vect = classification.text2vec(X_test, wv)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_vect_avg = classification.average_vector(X_train_vect)\n",
    "X_test_vect_avg = classification.average_vector(X_test_vect)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classification reports:\n",
    "- Recall = how many of this class where found over whole num of elements of this class\n",
    "- Precision = how many correclty classified among that class\n",
    "- f1-score: harmonic mean between precision and recall\n",
    "- support: num of occurence of given class in dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instantiate and fit a basic Random Forest model on top of the vectors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = classification.classify_predict(X_train_vect_avg, X_test_vect_avg, y_train, \"Random Forest\")\n",
    "classification.print_classification_report(y_test, y_pred)\n",
    "\n",
    "y_pred = classification.classify_predict(X_train_vect_avg, X_test_vect_avg, y_train, \"Multinomial Naive Bayes\")\n",
    "classification.print_classification_report(y_test, y_pred)\n",
    "\n",
    "y_pred = classification.classify_predict(X_train_vect_avg, X_test_vect_avg, y_train, \"SVM\")\n",
    "classification.print_classification_report(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train.value_counts().plot.pie(autopct='%0.2f')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Highly Imbalanced Dataset!\n",
    "Ideas:\n",
    "- Undersampling: reduce majority class to make it equal to minority class\n",
    "- Oversampling: increase minority class to make it equal to majority class through resampling\n",
    "- K-fold cross validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Oversampling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy=\"not majority\")\n",
    "X_train_2d = X_train.values.reshape(-1, 1) # puts each elem of array in own array\n",
    "X_res, y_res = ros.fit_resample(X_train_2d, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_res.value_counts()\n",
    "y_res.value_counts().plot.pie(autopct='%0.2f')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#X_res revert 2_dimensionality\n",
    "X_res_1d = X_res.flatten()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# classification with resampled vectors\n",
    "X_res_vect = classification.text2vec(X_res_1d, wv)\n",
    "X_res_vect_avg = classification.average_vector(X_res_vect)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classification reports:\n",
    "- Recall = how many of this class where found over whole num of elements of this class\n",
    "- Precision = how many correclty classified among that class\n",
    "- f1-score: harmonic mean between precision and recall\n",
    "- support: num of occurence of given class in dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_res_pred = classification.classify_predict(X_res_vect_avg, X_test_vect_avg, y_res, \"Random Forest\")\n",
    "classification.print_classification_report(y_test, y_res_pred)\n",
    "y_res_pred = classification.classify_predict(X_res_vect_avg, X_test_vect_avg, y_res, \"Multinomial Naive Bayes\")\n",
    "classification.print_classification_report(y_test, y_res_pred)\n",
    "y_res_pred = classification.classify_predict(X_res_vect_avg, X_test_vect_avg, y_res, \"SVM\")\n",
    "classification.print_classification_report(y_test, y_res_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: try\n",
    "#from imblearn.pipeline import Pipeline\n",
    "# create pipeline for handling imbalanced data\n",
    "#steps = [('over', RandomOverSampler()), ('model', DecisionTreeClassifier())]\n",
    "#pipeline = Pipeline(steps=steps)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification with pretrained model\n",
    "to be continued.."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Model with pretrained vectors (just english)\n",
    "# try fasttext vectors in several languages\n",
    "# bert has multilingual CONTEXTUAL word vectors (later;))\n",
    "# use pretrained glove vectors\n",
    "# by downloading them manually\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from pathlib import Path\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "file_path: Path = Path(\"../models/word_vectors/glove.6B.100d.txt\").resolve()\n",
    "glove_file = datapath(file_path)\n",
    "tmp_file = get_tmpfile(\"glove2word2vec.txt\")\n",
    "_ = glove2word2vec(glove_file, tmp_file)\n",
    "\n",
    "pretrained_model = ttl_word2vec.load_word2vec_keyed_vectors(tmp_file)\n",
    "\n",
    "# save when created first\n",
    "pretrained_model.save(\"../models/word_vectors/pretrained_model.kv\")\n",
    "# load when file already exists\n",
    "pretrained_model= ttl_word2vec.load_word2vec_keyed_vectors(\"../models/word_vectors/pretrained_model.kv\")\n",
    "\n",
    "#missing_words = ttl_word2vec.get_words_in_static_embeddings(pretrained_model, words, '../models/words/pretrained_model.txt')\n",
    "\n",
    "\"\"\"# TODOS:\n",
    "# add bigram detector?\n",
    "# add missing word if occurs e.g. 3 times? if possible and makes sense...\n",
    "sentences =[[\"test\"]]\n",
    "model.build_vocab(sentences)\n",
    "model.intersect_word2vec_format(pretrained_model, lockf=1.0, binary=True)\n",
    "model.train(sentences, total_examples=3, epochs = 5)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis] *",
   "language": "python",
   "name": "conda-env-thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}